---
layout: post
author: ledinhtrunghieu
title: Remarkable Posts in Data Engineering SubReddit
---

# 1. Help

[Is it possible to create a real time data pipeline that collects and uploads data to a database?](https://www.reddit.com/r/dataengineering/comments/o0momn/is_it_possible_to_create_a_real_time_data/)
*Hi, everyone. I'm trying to work on a project in my free time. I want to create a data pipeline that uploads a file from a directory to a database. I was thinking of creating a REST API connected to PostgreSQL however I'm not sure if an API can carry out this task. My question is, is it possible to achieve this with a REST API that autmatically uploads the data to a data base and maybe records the time the upload is carried out? Thank you in advance*
* This is possible. You can easily achieve "near realtime" by creating the API call that loads data into the database, then using any scheduling tool to run it every N minutes. I'd usually use AWS or azure, but there's other low-overhead options out there.
* For true realtime/streaming data you should look into apache kafka. You'll want a proper processing engine to pull the data. It's much more work to configure and setup, but if you want a project to do true data streaming it could be worth it.


# 2. Discussion

# 3. Blog

# 4. Career

[How to efficiently evaluate a candidate Python proficiency?](https://www.reddit.com/r/dataengineering/comments/o0dkpc/how_to_efficiently_evaluate_a_candidate_python/)

**Questions:**
1. What is the difference between a tuple and a list?
2. What is a generator?
3. What is a context manager?
4. How do you manage dependencies in your Python projects?
5. What are your favorite and least favorite features of the language?
6. What is your favorite Python package and why?

**Answers:**
1. The main difference is that lists are mutable while tuples are not. Tuples send a signal to the person reading the code that the data should be static and provides some runtime safety. Tuples use less memory and are a bit faster which can make a big difference when performance is needed. Lists have more operations than tuples though so sometimes lists are easier to work with even when dealing with static data.
2. A generator is a function that can be used as a lazy iterator. This means you can use it in a for loop and have the values being iterated over generated on demand, resulting in lower memory usage and improved performance. This makes controlling memory usage much simpler in programs that need it.
3. Context managers allow you to allocate and release resources in a simple way via the "with" statement. This is useful for managing long-running connections or cleaning up temporary resources like files or directories.
4. I install dependencies with pip, manage python versions with pyenv, and keep a requirements.txt file with a list of dependencies in all my projects that are used in a setup.py script.
5. My favorite features of the language are decorators, comprehensions, generators, data classes, and context managers! They are great ways of solving common programming problems in a succinct fashion. The interpreter is also fast which makes the program start time low, which is perfect for scripting and iterating quickly. The REPL is also good and iPython notebooks are useful. My least favorite features are the lack of functional programming tools, specifically for immutable programming, the GIL, and an overall subpar concurrency model.
6. smart-open/fs-spec. I work with files in cloud storage a lot and having the same APIs for working with local files is a huge productivity gain.


# 5. Interview

# 6. Meme
 
# 7. Meta





